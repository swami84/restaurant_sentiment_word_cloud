{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af269a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "import  pyspark.sql.functions as F\n",
    "from pyspark.sql import SQLContext, SparkSession\n",
    "\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45d0ebf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://host.docker.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Spark NLP</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x204db8aca60>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Starting Spark Session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Spark NLP\")\\\n",
    "    .config(\"spark.driver.memory\",\"16G\")\\\n",
    "    .config('spark.executor.memory', '8G') \\\n",
    "    .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.12:3.3.0\") \\\n",
    "    .getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36a7057b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Restaurants =  60715\n"
     ]
    }
   ],
   "source": [
    "rest_attrs_file = '../data/input/rest_attrs_filtered.json/'\n",
    "df_rest_attrs =  spark.read.option(\"multiLine\", \"false\").option(\"mode\", \"PERMISSIVE\").json(rest_attrs_file)\n",
    "rest_count = df_rest_attrs.count()\n",
    "print('Total Restaurants = ', rest_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5e314fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Raw Reviews =  19567851\n"
     ]
    }
   ],
   "source": [
    "op_path = '../../rest_type classification/data/input/review_files/'\n",
    "op_files = [op_path + f for f in os.listdir(op_path) ]\n",
    "df_reviews = spark.read.parquet(*op_files)\n",
    "print('Total Number of Reviews = ',df_reviews.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "07decd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_reviews(df_rest_attributes, df_rest_reviews):\n",
    "    df_rem_dup = df_rest_reviews.drop_duplicates(subset = ['place_id', 'review_id'])\n",
    "\n",
    "    df_filter_rev = df_rem_dup.withColumn('Review_Length', F.length('review')).filter(F.col('Review_Length') >30)\n",
    "    df_merge_rest_type_revs = df_rest_attributes.select('place_id', 'rest_type','rest_summary')\\\n",
    "                    .join(df_filter_rev.select('place_id', 'review','rating'), 'place_id', 'inner')\n",
    "    \n",
    "    return df_merge_rest_type_revs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "22615392",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(df_rest_reviews):\n",
    "    from pyspark.ml.feature import Tokenizer, StopWordsRemover, RegexTokenizer\n",
    "    rest_types = [row.rest_type for row in df_rest_attrs.select(\"rest_type\").distinct().collect()]\n",
    "    stopwordList = [\"good\",\"food\",\"yet\", \"place\",\"translated\", 'tasty', 'amazing', 'one', 'especially', 'definitely',\n",
    "                    'best', 'really','excellent', 'love', 'restaurant', 'awesome','coming','think', 'though',\n",
    "                    'perfect','taste', 'eat', 've', 'got', 'location', 'first', 'time','go', 'back','yummy','liked',\n",
    "                    'know', 'everything', 'need', 'came', 'come','loved', 'enjoy', 'well','better','make', 'sure', 'want',\n",
    "                    'try', 'meal','thing', 'much', 'll', 'say','even','probably', 'must', 'tasted', 'visit', 'wow','ask',\n",
    "                    'never', 're', 'd', 'ask', 'asked','went', 'visit', 'person', 'people', 'absolutely','look', 'looked',\n",
    "                    'friend', 'wife','went','made', 'ok','ate', 'eating', 'eat','wasn', 'didn', 'm', 'way','left','use',\n",
    "                    'actually', \"google\", 'great', 'delicious', 'like' , 'lot', 'still', 'thank','won', 'nothing','see',\n",
    "                    'gave', 'guy', 'cook', 'last', 'top', 'used','enjoyed', 'least', 'little', 'thought', 'guess','tried',\n",
    "                    'return', 'tried','told','tell','point','okay', 'instead', 'ordering', 'anything','every', 'seem', \n",
    "                    'something', 'husband', 'leave', 'right', 'second', 'call', 'served','couldn','waiter', 'waitress',\n",
    "                    'bad', 'give', 'awful','disappoint', 'disappointing','usually', 'pretty','awful','let','sorry',\n",
    "                    'said', 'maybe', 'someone', 'table', 'dont', 'done', 'table','worst', 'attitude','plate', 'maybe',\n",
    "                    'server', 'wanted','unfortunately', 'horrible', 'menu', 'open', 'two','things', 'around', 'inside',\n",
    "                    'another', 'item', 'bit', 'called', 'everyone', 'given', 'walked', 'understand', 'us','seems', 'find',\n",
    "                    'put', 'alway','disappointed', 'u', 'put', 'literally', 'going' , 'ordered', 'like', 'either',\n",
    "                   'brought', 'feel', 'serve', 'saw', 'time','honestly', 'friends']  + rest_types\n",
    "    stopwordList.extend(StopWordsRemover().getStopWords())\n",
    "    df_rest_reviews_lower = df_rest_reviews.withColumn('review', F.lower(F.col('review')))\n",
    "    df_reviews_rem_html = df_rest_reviews_lower.select('place_id','rest_type', 'rating', \\\n",
    "                                  (F.lower(F.regexp_replace('review', \"<.*?>\", \" \")).alias('review')))\n",
    "    df_reviews_rem_symbols = df_reviews_rem_html.select('place_id','rest_type', 'rating', \\\n",
    "                               (F.lower(F.regexp_replace('review', \"[^a-zA-Z\\\\s]\", \" \")).alias('review')))\n",
    "\n",
    "    def filter_empty(l):\n",
    "        return filter(lambda x: x is not None and len(x) > 0, l)\n",
    "    \n",
    "\n",
    "    tokenizer = Tokenizer(inputCol=\"review\", outputCol=\"review_tokens\")\n",
    "    df_reviews_tokens = tokenizer.transform(df_reviews_rem_symbols).select('place_id','rest_type','rating','review_tokens')\n",
    "    remover = StopWordsRemover(inputCol='review_tokens', outputCol='words_clean',stopWords=stopwordList)\n",
    "    df_reviews_clean = remover.transform(df_reviews_tokens).select('place_id','rest_type','rating', 'words_clean')\n",
    "\n",
    "    df_clean_reviews = df_reviews_clean.withColumn(\"words_clean\", F.expr(\"filter(words_clean, elem -> elem != '')\"))\n",
    "    \n",
    "    return df_clean_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "4da1e89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spark_prep(df_rest_attributes, df_rest_reviews):\n",
    "    df_combined = clean_reviews(df_rest_attributes, df_rest_reviews)\n",
    "    df_clean_reviews = tokenize(df_combined)\n",
    "    return df_clean_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "ac300fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_reviews = spark_prep(df_rest_attrs, df_reviews)\n",
    "df_clean_reviews.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "0c16e055",
   "metadata": {},
   "outputs": [],
   "source": [
    "rest_types = [row.rest_type for row in df_clean_reviews.select('rest_type').distinct().collect()]\n",
    "for cuisine in rest_types:\n",
    "    pos_rev = [row.words_clean for row in df_clean_reviews.where('rest_type = \"{}\" and rating > 3'.format(cuisine)).select('words_clean').collect()]\n",
    "    neg_rev = [row.words_clean for row in df_clean_reviews.where('rest_type = \"{}\" and rating < 3'.format(cuisine)).select('words_clean').collect()]\n",
    "    pos = True\n",
    "    for rev in [pos_rev, neg_rev]:\n",
    "        rev_corpus = [(\" \").join(sl) for sl in rev]\n",
    "        vectorizer = TfidfVectorizer(stop_words='english', ngram_range = (1,2), min_df = .01)\n",
    "        \n",
    "        X = vectorizer.fit_transform(rev_corpus)\n",
    "        dense = X.todense()\n",
    "        denselist = dense.tolist()\n",
    "        feature_names = vectorizer.get_feature_names_out()\n",
    "        df = pd.DataFrame(denselist, columns=feature_names)\n",
    "\n",
    "        wordcloud = WordCloud(font_path = r'C:\\Windows\\Fonts\\Verdana.ttf',\n",
    "                            background_color = 'white',\n",
    "                            width = 1200,max_words = 100,\n",
    "                            height = 1000,\n",
    "                            collocation_threshold = 20           \n",
    "                            ).generate_from_frequencies(df.T.sum(axis=1))\n",
    "        sent = 'negative'\n",
    "        if pos:\n",
    "            sent = 'positive'\n",
    "            pos = False\n",
    "        os.makedirs('../data/output/wordclouds/{0}/'.format(cuisine),exist_ok=True)\n",
    "        op_fname = ('../data/output/wordclouds/{0}/{1}_{2}.png'.format(cuisine,cuisine,sent))\n",
    "        plt.figure(figsize = (12,10))\n",
    "        plt.imshow(wordcloud)\n",
    "        plt.axis('off')\n",
    "        plt.title('Wordcloud of Cuisine: {} , Sentiment: {}\"'.format(cuisine,sent))\n",
    "        plt.savefig(op_fname)\n",
    "        plt.close()\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
